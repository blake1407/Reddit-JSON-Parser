# import urllib library 
from urllib.request import urlopen 

#html parser
from html.parser import HTMLParser

#import dataclass
from dataclasses import dataclass

# import json 
import json 

#import html
import html

#import pandas
import pandas as pd

#import time
import time

#import literal_eval
from ast import literal_eval

# store the URL in url as  
# parameter for urlopen

# take_input = input("Please enter the url of the Reddit thread:")

# url = take_input.strip() + ".json"

url = "https://www.reddit.com/r/Brazil/comments/yhtimr/lula_stages_astonishing_comeback_to_beat_farright/.json"
# url = "https://www.reddit.com/r/ForTheKing/comments/bup98d/lore_store_unlocks_verified/.json"

title = url.split("/")[-2]
  
# store the response of URL 
response = urlopen(url) 
  
# storing the JSON response  
# from url in data 
data_json = str(json.loads(response.read()))
  
# print the json response 
# print(data_json) 

"""

This is parsing ONLY the OG post section, not the comment section.
The reason is that the buildin HTMLParser does not parse the correct 
code section of the OG's post, only the replies. 

"""
unescaped = html.unescape(data_json)

def remove_extras(x):
    '''
    This function removes the extras character leftover from
    the html parser.
    
    Args:
        x (str): any string.
    Returns:
        str: corrected string.
    '''
    y = x.replace("'", "").replace("}}]", "").replace("}}", "").replace("\\n\\n", "").replace('\'', "'").replace(" \'", "'").replace(":\'", "").replace("\\", "").replace("> ", "").strip()
    return y

poster_body = str(literal_eval(unescaped)[0])
poster_code = remove_extras(poster_body)

def find_subreddit_name(ogpost: list) -> str:
    """
    Find the subreddit name of the post.
    """
    ogpost_in_list = [ogpost]
    for code in ogpost_in_list:
        splitted = code.split(",")
    for split in splitted:
        if split.startswith(" subreddit:"):
            subreddit_name = split.split(":")[-1].strip()
    return subreddit_name

subreddit_name = find_subreddit_name(poster_code)

@dataclass 
class parsed_values:
    subreddit: str
    author: str
    author_fullname: str
    name: str
    parent_id: str
    created_time: str
    score: str
    upvote_ratio: float
    body: str

f = open('unwanted_values.txt', 'r')
unwanted_value = f.read()

og_post_with_table = []
og_post_without_table = []

# for f in poster_code:
#     """
#     If it does starts with "[{kind: ", then the post has no tables.
#     Therefore, if it doesnt, it does have a table.
#     """
#     if not f.startswith("[{kind: ") or not f.startswith("{'kind': "):

#         poster_post = poster_body.split("&#x200B;")[:-1]

#         def check_for_tables (sections: list) -> list:
#             '''
#             This function checks whether OG post has a table.
#             If there's a table, it will be return as the first index of
#             the output list. Otherwise, the essay portion will be separated
#             for each paragraph in the output list.  
            
#             Args:
#                 sections (str): (poster_post) parsed code of the OG post.
#             Returns:
#                 list: list separated by paragraph.
#             '''
#             all = []
#             table = []
#             essay = []
#             together = []
#             for section in sections:
#                 all.append(section.split("\\n\\n"))
#             for a in all:
#                 for each in a:
#                     if each.startswith("|") and each.endswith("|"):
#                         table.append(each)
#                     else:
#                         essay.append(each)
#             if len(table) >= 1:
#                 together = table + essay
#             else:
#                 together.append(essay)
#             return together

#         check_for_tables(poster_post)

#         table = check_for_tables(poster_post)[0]
#         essays = check_for_tables(poster_post)[1:]

#         def get_columns(line: str, number: int) -> list:
#             columns = []
#             items = line[number].split("|")
#             for item in items:
#                 if item != "" and item != ":-": 
#                     columns.append(item)
#             return columns

#         def get_line_data(data: str):
#             data_list = []
#             for i in range(len(data)-1):
#                 column = get_columns(data, i)
#                 if len(column)>0:
#                     data_list.append(column)
#             return data_list

#         def create_table(data: str):
#             splitted_lines = get_line_data(data)
#             header = splitted_lines[0]
#             data = splitted_lines[1:]
#             filename = title + "'s table.csv"
#             with open(filename, 'w') as file:
#                 for header in header:
#                     file.write(str(header)+', ')
#                 file.write('\n')
#                 for row in data:
#                     for x in row:
#                         file.write(str(x)+', ')
#                     file.write('\n')

#         def table_to_csv(table: str):
#             splitted_text = table.split("\\n")
#             create_table(splitted_text)
#             print("Table " + title + " has been created!")
        
#         if len(table)>0:
#             table_to_csv(table)

#         def essay_body (essays: list) -> str:
#             """
#             Return the OG Post essay portion as a string.
#             """
#             fixed = ""
#             for essay in essays:
#                 if not essay.startswith("[{'kind'"):
#                     e = essay.replace("**", "")
#                     fixed += e
#             return fixed

#         og_essay = essay_body(essays)
#         print(poster_body)
    
#         splitted_code = f.split(",")

#         def OG_filtering_values (codes: list) -> parsed_values:
#             og = []
#             a = ""
#             p_i = ""
#             d = 0
#             url = ""
#             for code in codes:
#                 wanted_value = code.split(":")

#                 if wanted_value[0] == " author":
#                     a = wanted_value[1].strip()

#                 elif wanted_value[0] == " author_fullname":
#                     a_f = wanted_value[1].strip()

#                 elif wanted_value[0] == " name":
#                     n = wanted_value[1].strip()

#                 elif wanted_value[0] == " created":
#                     x = wanted_value[1].strip()
#                     converted_time = str(time.strftime("%D %H:%M", time.localtime(float(x))))

#                 elif wanted_value[0] == " score":
#                     u = str(wanted_value[1].strip())

#                 elif wanted_value[0] == " upvote_ratio":
#                     d = str(wanted_value[1].strip())
                
#                 elif wanted_value[0] == " url_overridden_by_dest":
#                     url = "https:" + str(wanted_value[-1])
        
#             og = parsed_values(subreddit_name, a, a_f, n, p_i, converted_time, u, d, '"' + url + og_essay + '"')
#             return og
#         og_post_with_table = OG_filtering_values(splitted_code)

    # else:
body = ""
splitted = poster_body.split("'user_reports': []")
parse_for_body = splitted[0].split("'selftext': ")
body = parse_for_body[-1]
if body.endswith(", "):
    body = body[:-2]
if body.endswith(","):
    body = body[:-1]
split = splitted[-1].split(",")

def OG_filtering_values (codes: list) -> parsed_values:
    og = []
    a = ""
    p_i = ""
    for code in codes:
        wanted_value = code.split(":")
        if wanted_value[0] == " 'author'":
            a = wanted_value[1].strip()

        elif wanted_value[0] == " 'author_fullname'":
            a_f = wanted_value[1].strip()

        elif wanted_value[0] == " 'name'":
            n = wanted_value[1].strip()

        elif wanted_value[0] == " 'created'":
            x = wanted_value[1].strip()
            converted_time = str(time.strftime("%D %H:%M", time.localtime(float(x))))

        elif wanted_value[0] == " 'score'":
            u = str(wanted_value[1].strip())

        elif wanted_value[0] == " 'upvote_ratio'":
            d = str(wanted_value[1].strip())

        elif wanted_value[0] == " 'url'":
            url = "https:" + str(wanted_value[-1].strip())
            if url[-1] == "'":
                url = url[:-1]
        
    og = parsed_values(subreddit_name, a, a_f, n, p_i, converted_time, u, d, '"'  + url + "\n" + body + '"')
    return og

og_post_without_table = OG_filtering_values(split)

